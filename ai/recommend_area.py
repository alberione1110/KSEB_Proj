import os
import time
import json
import numpy as np
import pandas as pd
from sqlalchemy import create_engine
from sklearn.preprocessing import MinMaxScaler
import google.generativeai as genai
# from openai import OpenAI   # í•„ìš” ì‹œ ì‚¬ìš©
import pymysql

from config.settings import get_engine  # âœ… DB URL/Engineì€ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ


def run_recommendation(category_small, gu_name):
    """
    - ë¯¼ê°ì •ë³´(í˜¸ìŠ¤íŠ¸/ê³„ì •/ë¹„ë²ˆ/APIí‚¤) ì œê±°: config.settings / .env ì‚¬ìš©
    - SQL ì¸ì ì…˜ ë°©ì§€: ëª¨ë“  ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©
    - ìºì‹œëŠ” ./cache í´ë”ì— ì €ì¥
    """
    # â”€â”€ DB ì—”ì§„ (í™˜ê²½ë³€ìˆ˜ ë¡œë“œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    engine = get_engine()

    # â”€â”€ (ì„ íƒ) ì—°ê²° í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        with engine.connect() as conn:
            conn.execute("SELECT 1")
        print("âœ… DB ì—°ê²° í™•ì¸")
    except Exception as e:
        print("âŒ DB ì—°ê²° ì‹¤íŒ¨:", e)
        raise

    # â”€â”€ êµ¬(region_code) ì¡°íšŒ: íŒŒë¼ë¯¸í„° ë°”ì¸ë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sql_gu_code = """
        SELECT DISTINCT region_code
        FROM floating_population_stats
        WHERE region_name = %s
        LIMIT 1
    """
    gu_code_df = pd.read_sql_query(sql_gu_code, engine, params=(gu_name,))
    if gu_code_df.empty:
        raise ValueError(f"region_name '{gu_name}'ì— í•´ë‹¹í•˜ëŠ” region_codeë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    gu_code = str(gu_code_df.iloc[0]['region_code'])

    print(f"ì„ íƒí•œ êµ¬ '{gu_name}'ì˜ ì§€ì—­ ì½”ë“œ: {gu_code}")
    print(f"ì„ íƒí•œ ì—…ì¢…: {category_small}")

    # â”€â”€ ìºì‹œ ë””ë ‰í„°ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    os.makedirs("cache", exist_ok=True)

    # â”€â”€ ìºì‹œ/ì¡°íšŒ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def load_or_cache_query(name, table_name):
        path = f"cache/{name}.feather"
        if os.path.exists(path):
            print(f"ğŸ“‚ ìºì‹œ ë¶ˆëŸ¬ì˜´(ì›ë³¸ ì „ì²´): {name}")
            return pd.read_feather(path)

        print(f"ğŸ’¾ ì›ë³¸ ì „ì²´ ë°ì´í„° ì €ì¥: {name}")
        df = pd.read_sql(f"SELECT * FROM {table_name}", engine)
        df.to_feather(path)
        return df

    def query_table(
        table_name,
        extra_condition="",
        category_col='category_small',
        indicator_col='indicator',
        indicator_val=None,
        columns='*'
    ):
        # âš ï¸ ë¬¸ìì—´ ì´ì–´ë¶™ì´ê¸° ëŒ€ì‹  íŒŒë¼ë¯¸í„° ë°”ì¸ë”© ì‚¬ìš©
        base = f"SELECT {columns} FROM {table_name} WHERE region_code LIKE %s"
        params = [f"{gu_code}%"]

        if category_small and category_col:
            base += f" AND {category_col} = %s"
            params.append(category_small)

        if indicator_val and indicator_col:
            base += f" AND {indicator_col} = %s"
            params.append(indicator_val)

        if extra_condition:
            base += f" AND {extra_condition}"

        base += " ORDER BY region_code, year, quarter"
        return pd.read_sql_query(base, engine, params=tuple(params))

    def load_table(table_name):
        try:
            return pd.read_sql(f"SELECT * FROM {table_name}", engine)
        except Exception as e:
            print(f"âŒ [ERROR] í…Œì´ë¸” {table_name} ë¡œë”© ì‹¤íŒ¨:", e)
            engine.dispose()
            raise

    def add_region_service_names(df, zone_df, service_df, rent_df):
        df['zone_id'] = df['zone_id'].astype(str)
        zone_df['zone_id'] = zone_df['zone_id'].astype(str)

        df = df.merge(zone_df[['zone_id', 'region_name']], on='zone_id', how='left')
        rent_test_df = rent_df[['region_name', 'region_code']].drop_duplicates(subset=['region_name', 'region_code'])
        df = df.merge(rent_test_df[['region_name', 'region_code']], on='region_name', how='left')
        df = df[df['region_code'].notna()]
        df = df.merge(service_df[['service_code', 'service_name']], on='service_code', how='left')

        # ì›ë˜ ì½”ë“œì— category_small+'\r' ë¹„êµê°€ ìˆì—ˆëŠ”ë°, ë°ì´í„° ì •í•©ì„± ì´ìŠˆ ê°€ëŠ¥.
        # ê°œí–‰/ìºë¦¬ì§€ë¦¬í„´ ì œê±° í›„ ë¹„êµë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ ë³€ê²½.
        df['service_name'] = df['service_name'].astype(str).str.replace(r'[\r\n]+', '', regex=True)
        return df[df['service_name'] == category_small]

    # â”€â”€ í’€í…Œì´ë¸” 1íšŒ ìºì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    t0 = time.time()
    pop_full_df     = load_or_cache_query("pop_df",      "floating_population_stats")
    rent_full_df    = load_or_cache_query("rent_df",     "rental_price_stats")
    age_full_df     = load_or_cache_query("age_df",      "subcategory_avg_operating_period_stats")
    store_full_df   = load_or_cache_query("store_df",    "subcategory_store_count_stats")
    survive_full_df = load_or_cache_query("survive_df",  "subcategory_startup_survival")
    openclose_full_df = load_or_cache_query("openclose_df", "subcategory_openclose_stats")

    zone_df    = load_table('zone_table')
    zone_df['zone_id']= zone_df['zone_id'].astype(str)
    service_df = load_table('service_type')

    # â”€â”€ ìµœê·¼ 4ê°œ ë¶„ê¸° í•„í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    recent_periods = (
        pop_full_df[['year', 'quarter']]
        .drop_duplicates()
        .sort_values(['year', 'quarter'], ascending=False)
        .head(4)
        .sort_values(['year', 'quarter'])
    )
    recent_period_tuples = set(map(tuple, recent_periods.to_numpy()))

    def filter_recent_quarters(df):
        return df[df[['year', 'quarter']].apply(tuple, axis=1).isin(recent_period_tuples)]

    def get_pop_df(full_df, gu_code):
        full_df['region_code'] = full_df['region_code'].astype(str)
        return full_df[full_df['region_code'].str.startswith(str(gu_code))]

    def get_rent_df(full_df, gu_code):
        full_df['region_code'] = full_df['region_code'].astype(str)
        return full_df[full_df['region_code'].str.startswith(str(gu_code))]

    def get_age_df(full_df, gu_code, category_small):
        full_df['region_code'] = full_df['region_code'].astype(str)
        return full_df[
            full_df['region_code'].str.startswith(str(gu_code)) &
            (full_df['category_small'] == category_small) &
            (full_df['indicator'] == 'avg_operating_years_30')
        ]

    def get_store_df(full_df, gu_code, category_small):
        full_df['region_code'] = full_df['region_code'].astype(str)
        return full_df[
            full_df['region_code'].str.startswith(str(gu_code)) &
            (full_df['category_small'] == category_small) &
            (full_df['indicator'] == 'store_total')
        ]

    def get_survive_df(full_df, gu_code, category_small):
        full_df['region_code'] = full_df['region_code'].astype(str)
        return full_df[
            full_df['region_code'].str.startswith(str(gu_code)) &
            (full_df['category_small'] == category_small)
        ]

    def get_openclose_df(full_df, gu_code, category_small):
        full_df['region_code'] = full_df['region_code'].astype(str)
        return full_df[
            full_df['region_code'].str.startswith(str(gu_code)) &
            (full_df['category_small'] == category_small)
        ]

    pop_filtered     = filter_recent_quarters(get_pop_df(pop_full_df, gu_code))
    rent_filtered    = filter_recent_quarters(get_rent_df(rent_full_df, gu_code))
    age_filtered     = filter_recent_quarters(get_age_df(age_full_df, gu_code, category_small))
    store_filtered   = filter_recent_quarters(get_store_df(store_full_df, gu_code, category_small))
    survive_filtered = filter_recent_quarters(get_survive_df(survive_full_df, gu_code, category_small))
    openclose_filtered = filter_recent_quarters(get_openclose_df(openclose_full_df, gu_code, category_small))

    # â”€â”€ ë§¤ì¶œ í…Œì´ë¸”(ì—°ë„ë³„) ìºì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    years = [2022, 2023, 2024]
    def load_or_cache_table(table_name, year):
        filename = f"cache/{table_name}_{year}.feather"
        if os.path.exists(filename):
            return pd.read_feather(filename)
        df = pd.read_sql(f"{'SELECT * FROM ' + table_name + '_' + str(year)}", engine)
        df.to_feather(filename)
        return df

    zone_store_count_all   = pd.concat([load_or_cache_table("zone_store_count", year).assign(year=year) for year in years])
    sales_by_gender_age_all= pd.concat([load_or_cache_table("sales_by_gender_age", year).assign(year=year) for year in years])
    summary_sales_all      = pd.concat([load_or_cache_table("sales_summary", year).assign(year=year) for year in years])

    # â”€â”€ ê³µí†µ ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for df in (sales_by_gender_age_all, summary_sales_all, zone_store_count_all):
        df['zone_id'] = df['zone_id'].astype(str)

    gender_known_all   = sales_by_gender_age_all[sales_by_gender_age_all['gender'].isin(['ì—¬ì„±', 'ë‚¨ì„±'])]
    gender_unknown_all = sales_by_gender_age_all[~sales_by_gender_age_all['gender'].isin(['ì—¬ì„±', 'ë‚¨ì„±'])]

    gender_known_all   = add_region_service_names(gender_known_all, zone_df, service_df, rent_full_df)
    gender_unknown_all = add_region_service_names(gender_unknown_all, zone_df, service_df, rent_full_df)

    def merge_sales_with_store(df, group_cols, sales_col='sales_amount'):
        df = df.merge(
            zone_store_count_all[['zone_id', 'service_code', 'year', 'quarter', 'count']],
            on=['zone_id', 'service_code', 'year', 'quarter'],
            how='inner'
        )
        df['avg_sales_per_store'] = df[sales_col] / df['count']
        return df

    # ì„±ë³„ë³„
    gender_all = merge_sales_with_store(gender_known_all, ['zone_id', 'service_code', 'year', 'quarter'])
    gender_all = gender_all[gender_all['region_code'].astype(str).str.startswith(gu_code)]
    gender_all = gender_all[["region_name", "zone_id", "service_name", "service_code", "year", "quarter", "gender", "avg_sales_per_store", "count"]]
    gender_sales = {year: gender_all[gender_all['year'] == year].reset_index(drop=True) for year in years}

    # ì—°ë ¹ëŒ€ë³„
    age_all = merge_sales_with_store(gender_unknown_all, ['zone_id', 'service_code', 'year', 'quarter'])
    age_all = age_all[age_all['region_code'].astype(str).str.startswith(gu_code)]
    age_all = age_all[["region_name", "zone_id", "service_name", "service_code", "year", "quarter", "age_group", "avg_sales_per_store", "count"]]
    age_sales = {year: age_all[age_all['year'] == year].reset_index(drop=True) for year in years}

    # ì „ì²´ ìš”ì•½
    summary_sales_all = summary_sales_all[summary_sales_all['service_name'] == category_small]
    summary_sales_all = merge_sales_with_store(summary_sales_all, ['zone_id', 'service_code', 'year', 'quarter'], sales_col='monthly_sales')
    summary_sales_all = summary_sales_all[["region_name", "zone_id", "service_name", "service_code", "year", "quarter", "avg_sales_per_store", "count"]]
    summary_sales = {year: summary_sales_all[summary_sales_all['year'] == year].reset_index(drop=True) for year in years}

    # â”€â”€ í†µê³„/ì ìˆ˜ ê³„ì‚°(ê¸°ì¡´ ë¡œì§ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def get_avg_fast(df, group_col='region_code', val_col=None, rename_col=None):
        df = df[[group_col, 'region_name', val_col]].copy()
        df[val_col] = pd.to_numeric(df[val_col], errors='coerce')
        df = df[df[val_col].notna()]
        grouped = df.groupby(group_col, sort=False).agg({val_col: 'mean', 'region_name': 'first'}).reset_index()
        if rename_col:
            grouped = grouped.rename(columns={val_col: rename_col})
        return grouped

    def get_group_avg(df, group_col, rename_map: dict, round_digits=2):
        agg_dict = {col: 'mean' for col in rename_map.keys()}
        agg_dict['region_name'] = 'first'
        grouped = df.groupby(group_col, sort=False).agg(agg_dict).reset_index()
        grouped = grouped.rename(columns=rename_map)
        return grouped.round(round_digits)

    pop_avg   = get_avg_fast(pop_filtered,   val_col='floating_population', rename_col='ìœ ë™ì¸êµ¬')
    rent_avg  = get_avg_fast(rent_filtered,  val_col='rent_total',          rename_col='ì„ëŒ€ì‹œì„¸')
    age_avg   = get_avg_fast(age_filtered,   val_col='value',               rename_col='í‰ê· ì˜ì—…ê¸°ê°„(ë…„)')
    store_avg = get_avg_fast(store_filtered, val_col='value',               rename_col='ì í¬ìˆ˜')

    survive_avg   = get_group_avg(survive_filtered, 'region_code', {'survival_1yr': '1ë…„ ìƒì¡´ìœ¨(%)','survival_3yr': '3ë…„ ìƒì¡´ìœ¨(%)','survival_5yr': '5ë…„ ìƒì¡´ìœ¨(%)'})
    openclose_avg = get_group_avg(openclose_filtered, 'region_code', {'num_open': 'í‰ê·  ê°œì—…ìˆ˜','num_close': 'í‰ê·  íì—…ìˆ˜'})

    from functools import reduce
    dfs = [pop_avg, rent_avg, age_avg, store_avg, survive_avg, openclose_avg]
    merged_df = reduce(lambda L, R: pd.merge(L, R, on=['region_code', 'region_name'], how='inner', sort=False), dfs)
    merged_df = merged_df.rename(columns={'region_code': 'í–‰ì •ë™ì½”ë“œ', 'region_name': 'í–‰ì •ë™ëª…'}).sort_values(by='ìœ ë™ì¸êµ¬', ascending=False, ignore_index=True)

    # ë§¤ì¶œ í‰ê· ë“¤
    def get_avg_sales_fast(sales_df, group_col):
        sales_df = sales_df[['region_name', 'service_name', 'service_code', group_col, 'avg_sales_per_store']].copy()
        sales_df['avg_sales_per_store'] = pd.to_numeric(sales_df['avg_sales_per_store'], errors='coerce')
        sales_df = sales_df.dropna(subset=['avg_sales_per_store'])
        out = (
            sales_df.groupby(['region_name', group_col], sort=False)
            .agg({'avg_sales_per_store':'mean','service_name':'first','service_code':'first'})
            .reset_index()
        )
        out['avg_sales_per_store'] = (out['avg_sales_per_store'] / 3).round(2)
        return out

    def get_avg_sales_sum_fast(sales_df):
        sales_df = sales_df[['region_name', 'service_name', 'service_code', 'avg_sales_per_store']].copy()
        sales_df['avg_sales_per_store'] = pd.to_numeric(sales_df['avg_sales_per_store'], errors='coerce')
        sales_df = sales_df.dropna(subset=['avg_sales_per_store'])
        out = (
            sales_df.groupby('region_name', sort=False)
            .agg({'avg_sales_per_store':'mean','service_name':'first','service_code':'first'})
            .reset_index()
        )
        out['avg_sales_per_store'] = (out['avg_sales_per_store'] / 3).round(2)
        return out

    gender_list, age_list, summary_list = [], [], []
    for year in years:
        g = get_avg_sales_fast(gender_sales[year], group_col='gender'); g['year'] = year; gender_list.append(g)
        a = get_avg_sales_fast(age_sales[year],   group_col='age_group'); a['year'] = year; age_list.append(a)
        s = get_avg_sales_sum_fast(summary_sales[year]); s['year'] = year; summary_list.append(s)

    gender_df  = pd.concat(gender_list, ignore_index=True).rename(columns={'region_name':'í–‰ì •ë™ëª…','service_name':'ì—…ì¢…ëª…','service_code':'ì—…ì¢…ì½”ë“œ','gender':'ì„±ë³„','avg_sales_per_store':'ì„±ë³„ë³„ í‰ê·  ì›” ë§¤ì¶œ'})
    age_df     = pd.concat(age_list,    ignore_index=True).rename(columns={'region_name':'í–‰ì •ë™ëª…','service_name':'ì—…ì¢…ëª…','service_code':'ì—…ì¢…ì½”ë“œ','age_group':'ì—°ë ¹ëŒ€','avg_sales_per_store':'ì—°ë ¹ëŒ€ë³„ í‰ê·  ì›” ë§¤ì¶œ'})
    summary_df = pd.concat(summary_list, ignore_index=True).rename(columns={'region_name':'í–‰ì •ë™ëª…','service_name':'ì—…ì¢…ëª…','service_code':'ì—…ì¢…ì½”ë“œ','avg_sales_per_store':'í‰ê·  ì›” ë§¤ì¶œ'})

    gender_df.to_json('gender_avg_sales_dong.json',  orient='records', force_ascii=False, indent=4)
    age_df.to_json('age_avg_sales_dong.json',       orient='records', force_ascii=False, indent=4)
    summary_df.to_json('summary_avg_sales_dong.json',orient='records', force_ascii=False, indent=4)

    pivot_summary = (
        summary_df
        .pivot_table(index=['í–‰ì •ë™ëª…','ì—…ì¢…ëª…'], columns='year', values='í‰ê·  ì›” ë§¤ì¶œ', aggfunc='mean')
        .rename(columns={2022:'2022_í‰ê· ë§¤ì¶œ', 2023:'2023_í‰ê· ë§¤ì¶œ', 2024:'2024_í‰ê· ë§¤ì¶œ'})
        .reset_index()
    )

    merged_df = merged_df.merge(pivot_summary[['í–‰ì •ë™ëª…','2022_í‰ê· ë§¤ì¶œ','2023_í‰ê· ë§¤ì¶œ','2024_í‰ê· ë§¤ì¶œ']], on='í–‰ì •ë™ëª…', how='left')
    merged_df.to_json('merged_dong.json', orient='records', force_ascii=False, indent=4)

    score_columns   = ['ìœ ë™ì¸êµ¬','ì„ëŒ€ì‹œì„¸','í‰ê· ì˜ì—…ê¸°ê°„(ë…„)','ì í¬ìˆ˜','1ë…„ ìƒì¡´ìœ¨(%)','3ë…„ ìƒì¡´ìœ¨(%)','5ë…„ ìƒì¡´ìœ¨(%)','í‰ê·  ê°œì—…ìˆ˜','í‰ê·  íì—…ìˆ˜']
    score_columns_2 = ['2022_í‰ê· ë§¤ì¶œ','2023_í‰ê· ë§¤ì¶œ','2024_í‰ê· ë§¤ì¶œ']
    all_score_columns = score_columns + score_columns_2

    weights = {
        'ìœ ë™ì¸êµ¬': 0.2422, 'ì„ëŒ€ì‹œì„¸': -0.1453, 'í‰ê· ì˜ì—…ê¸°ê°„(ë…„)': 0.0484, 'ì í¬ìˆ˜': 0.3897,
        '1ë…„ ìƒì¡´ìœ¨(%)': 0.0182, '3ë…„ ìƒì¡´ìœ¨(%)': 0.0303, '5ë…„ ìƒì¡´ìœ¨(%)': 0.0484,
        'í‰ê·  ê°œì—…ìˆ˜': 0.0606, 'í‰ê·  íì—…ìˆ˜': -0.0347,
        '2022_í‰ê· ë§¤ì¶œ': 0.0870, '2023_í‰ê· ë§¤ì¶œ': 0.1275, '2024_í‰ê· ë§¤ì¶œ': 0.1275
    }

    norm_input = merged_df[all_score_columns].replace([np.inf,-np.inf], np.nan).fillna(0)
    scaler = MinMaxScaler()
    normalized_values = scaler.fit_transform(norm_input)
    normalized_df = pd.DataFrame(normalized_values, columns=[f'norm_{c}' for c in all_score_columns])

    merged_with_norm = pd.concat([merged_df.reset_index(drop=True), normalized_df], axis=1)
    weight_array = np.array([weights[c] for c in all_score_columns])
    norm_cols = [f'norm_{c}' for c in all_score_columns]
    merged_with_norm['í–‰ì •ë™_ì¶”ì²œì ìˆ˜'] = merged_with_norm[norm_cols].values.dot(weight_array)

    final_result = (
        merged_with_norm
        .drop(columns=norm_cols + ['ì—…ì¢…ëª…'])
        .loc[merged_with_norm['í–‰ì •ë™ì½”ë“œ'].astype(str).str.len() != 5]
        .replace([np.inf,-np.inf], np.nan)
        .dropna(subset=score_columns_2)
        .sort_values(by='í–‰ì •ë™_ì¶”ì²œì ìˆ˜', ascending=False)
        .reset_index(drop=True)
    )

    final_result.to_csv('filtered_result_dong.csv', index=False, encoding='utf-8-sig')
    final_result.to_json('filtered_result_dong.json', orient='records', force_ascii=False, indent=4)

    # â”€â”€ LLM ì„¤ì • (í™˜ê²½ë³€ìˆ˜) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(model_name="models/gemini-1.5-flash")

    few_shot_examples = """
    [ì˜ˆì‹œ 1]
    ì„œêµë™ì€ ì••ë„ì ì¸ ìœ ë™ì¸êµ¬ì™€ ë§¤ìš° ë†’ì€ ì›”ë§¤ì¶œì„ ë°”íƒ•ìœ¼ë¡œ ì»¤í”¼-ìŒë£Œ ìˆ˜ìš”ê°€ í’ë¶€í•œ í•µì‹¬ ìƒê¶Œì…ë‹ˆë‹¤.
    ì£¼ë³€ ìƒì£¼ ì¸êµ¬ ë° ì§ì¥ì¸ì´ ë§ì•„ í…Œì´í¬ì•„ì›ƒê³¼ íœ´ì‹ ìˆ˜ìš”ê°€ ê¾¸ì¤€í•˜ë©°, ë†’ì€ ì ì¬ ìˆ˜ìµì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    íŠ¹íˆ, íƒ€ ì§€ì—­ ëŒ€ë¹„ ë‚®ì€ ì„ëŒ€ì‹œì„¸ëŠ” ì•ˆì •ì ì¸ ìš´ì˜ í™˜ê²½ì„ ì œê³µí•˜ì—¬ ì°½ì—… ë¶€ë‹´ì„ ì¤„ì—¬ì¤ë‹ˆë‹¤.

    [ì˜ˆì‹œ 2]
    í–‰ë‹¹ë™ì€ ë§¤ìš° ë†’ì€ ìœ ë™ì¸êµ¬ì™€ í’ë¶€í•œ ë¯¸ìš©ì‹¤ ì í¬ìˆ˜ë¡œ ë¯¸ìš© ì„œë¹„ìŠ¤ì— ëŒ€í•œ íƒ„íƒ„í•œ ìˆ˜ìš”ê°€ í˜•ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    íŠ¹íˆ ì§€ì†ì ìœ¼ë¡œ ìƒìŠ¹í•˜ëŠ” ë†’ì€ í‰ê·  ì›”ë§¤ì¶œì€ ì••ë„ì ì¸ ìˆ˜ìµì„±ì„ ê¸°ëŒ€í•˜ê²Œ í•©ë‹ˆë‹¤.
    ì´ëŠ” í™œë°œí•œ ì†Œë¹„ë ¥ê³¼ ì—…ì¢… íŠ¹ì„±ì„ ê³ ë ¤í•  ë•Œ, ë¯¸ìš©ì‹¤ ì°½ì—…ì— ë§¤ìš° ìœ ë¦¬í•œ í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    def generate_region_summary(row, gu_name, category_small):
        weights_info = "ê°€ì¤‘ì¹˜ëŠ” ìœ ë™ì¸êµ¬(0.24), ì í¬ìˆ˜(0.39), 2024 í‰ê·  ë§¤ì¶œ(0.13) ë“±ì´ í½ë‹ˆë‹¤."
        prompt = f"""
        ë‹¹ì‹ ì€ ìƒê¶Œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ëŠ” '{gu_name}' ì§€ì—­ '{category_small}' ì—…ì¢…ì˜ íŠ¹ì • í–‰ì •ë™ í•µì‹¬ ìƒê¶Œ ì§€í‘œì…ë‹ˆë‹¤:

        ì°¸ê³ ìš© ì˜ˆì‹œë¥¼ í™•ì¸í•˜ì„¸ìš”:
        {few_shot_examples}

        ì•„ë˜ ì§€í‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìˆ˜ì¹˜ëŠ” ìµœì†Œí™”í•˜ê³ , '{category_small}' ì—…ì¢…ì— ì™œ ì í•©í•œì§€
        ì§€ì—­ íŠ¹ì„±ê³¼ ì—…ì¢… ìˆ˜ìš”ì˜ ì—°ê´€ì„±ì„ ë“¤ì–´
        í•µì‹¬ ì¥ì  2~3ê°œë¥¼ 3ì¤„ ì´ë‚´ë¡œ ê°„ê²°í•˜ê³  ê¸ì •ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

        - í–‰ì •ë™ëª…: {row['í–‰ì •ë™ëª…']}
        - ìœ ë™ì¸êµ¬: {int(row['ìœ ë™ì¸êµ¬']):,}ëª…
        - ì„ëŒ€ì‹œì„¸: {int(row['ì„ëŒ€ì‹œì„¸']):,}ì›/í‰
        - í‰ê· ì˜ì—…ê¸°ê°„: {row['í‰ê· ì˜ì—…ê¸°ê°„(ë…„)']}ë…„
        - ì í¬ìˆ˜: {row['ì í¬ìˆ˜']}ê°œ
        - 3ë…„ ìƒì¡´ìœ¨: {row['3ë…„ ìƒì¡´ìœ¨(%)']}%
        - 5ë…„ ìƒì¡´ìœ¨: {row['5ë…„ ìƒì¡´ìœ¨(%)']}%
        - í‰ê·  ê°œì—…ìˆ˜: {row['í‰ê·  ê°œì—…ìˆ˜']}ê°œ
        - í‰ê·  íì—…ìˆ˜: {row['í‰ê·  íì—…ìˆ˜']}ê°œ
        - 2022 í‰ê·  ì›”ë§¤ì¶œ: {int(row['2022_í‰ê· ë§¤ì¶œ']):,}ì›
        - 2023 í‰ê·  ì›”ë§¤ì¶œ: {int(row['2023_í‰ê· ë§¤ì¶œ']):,}ì›
        - 2024 í‰ê·  ì›”ë§¤ì¶œ: {int(row['2024_í‰ê· ë§¤ì¶œ']):,}ì›

        {weights_info}
        """
        response = model.generate_content(prompt)
        return response.text.strip()

    top_n = 5
    recommendation_list = []
    for _, row in final_result.head(top_n).iterrows():
        full_district_name = f"{gu_name} {row['í–‰ì •ë™ëª…']}"
        reason = generate_region_summary(row, gu_name, category_small)
        recommendation_list.append({'district': full_district_name, 'reason': reason})

    recommendation_dict = {category_small: recommendation_list}
    with open('recommendation_dong.json', 'w', encoding='utf-8') as f:
        json.dump(recommendation_dict, f, ensure_ascii=False, indent=4)

    print("âœ… JSON ì €ì¥ ì™„ë£Œ")
    print(json.dumps(recommendation_dict, ensure_ascii=False, indent=4))

    # í•¨ìˆ˜ ë°˜í™˜(í•„ìš” ì‹œ)
    return recommendation_dict
