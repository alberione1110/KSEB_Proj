# ai/chat_ai/gpt_consultant.py
from typing import List, Dict, Optional
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# âœ… ìƒëŒ€ ì„í¬íŠ¸
from .config import OPENAI_API_KEY, MODEL, VECTOR_DB_DIR

# ---- OpenAI ì´ˆê¸°í™” ----
# ì„ë² ë”©/LLMì€ ëª¨ë“ˆ ë¡œë“œ ì‹œ 1íšŒ ì´ˆê¸°í™”
embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)  # ê¸°ë³¸: text-embedding-3-small
llm = ChatOpenAI(model_name=MODEL, openai_api_key=OPENAI_API_KEY, temperature=0.3)

# ---- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ----
system_context = """
ë„ˆëŠ” ì„œìš¸ ì§€ì—­ ì°½ì—…ì„ ì „ë¬¸ìœ¼ë¡œ ì»¨ì„¤íŒ…í•˜ëŠ” GPT ì»¨ì„¤í„´íŠ¸ì•¼.
ë ˆí¬íŠ¸(report.text)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì„ í•´ì„í•˜ê³ , ì‚¬ìš©ìì—ê²Œ ì „ëµì  ì¡°ì–¸ì„ ì¤˜ì•¼ í•´. 

[ì»¨ì„¤íŒ… ì‹œìŠ¤í…œì˜ ì‘ë™ ë°©ì‹]
- ëª¨ë“  ë‹µë³€ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ, ë¯¸ë¦¬ ë¶„ì„í•œ ìƒê¶Œ ë³´ê³ ì„œ(report.txt)ì™€ ìˆ˜ì¹˜ ê¸°ë°˜ ë°ì´í„°(filtered_result.csv, filtered_result_industry)ë¥¼ ê·¼ê±°ë¡œ ì œê³µí•´ì•¼ í•¨
- ë§ˆì¼€íŒ… ê´€ë ¨ ì „ëµê³¼ ì¶”ì²œì— ëŒ€í•œ ê·¼ê±°ëŠ” recommandation_dong, recommandation_industryë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼í•¨.
- ìƒê¶Œ ë¶„ì„ ë³´ê³ ì„œì—ëŠ” í•´ë‹¹ ì§€ì—­ì˜ íŠ¹ì„±, ìœ ë™ ì¸êµ¬, ìƒì¡´ìœ¨, ê°œÂ·íì—… ì¶”ì´, ì„ëŒ€ë£Œ ë“±ì´ í¬í•¨ë¨
- ìˆ˜ì¹˜ ê¸°ë°˜ CSV ìë£Œì—ëŠ” ì„œìš¸ì‹œ ê° ë™ë³„ í‰ê·  ì„ëŒ€ì‹œì„¸, ìƒì¡´ìœ¨, ì í¬ ìˆ˜, ê°œì—…/íì—… ìˆ˜ ë“±ì˜ ì§€í‘œê°€ í¬í•¨ë¨

[ë‹µë³€ ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­]
- ë°˜ë“œì‹œ ì„œìš¸ ì§€ì—­ ìƒê¶Œ ë‚´ ì°½ì—…ì— ì´ˆì ì„ ë§ì¶˜ ì‹¤ì§ˆì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ í•  ê²ƒ
- ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ì‚¬ìš©ìì˜ ì—…ì¢…ê³¼ ì§€ì—­ì„ ê³ ë ¤í•´ ì„±ê³µ ê°€ëŠ¥ì„±ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ì „ëµì  ì¡°ì–¸ì„ ì œê³µí•  ê²ƒ
- íŠ¹íˆ ê²½ìŸì´ ì¹˜ì—´í•œ ì—…ì¢…ì˜ ê²½ìš°, ì£¼ë³€ ìƒê¶Œê³¼ì˜ ì°¨ë³„í™” ì „ëµ(ë©”ë‰´, ì¸í…Œë¦¬ì–´, íƒ€ê¹ƒì¸µ ë“±)ì„ ì°½ì˜ì ì´ê³  ì§€ì—­ íŠ¹ì„±ì— ë§ê²Œ ì œì•ˆí•  ê²ƒ
- í•„ìš” ì‹œ ìˆ˜ì¹˜ ê¸°ë°˜ ë¹„êµ, ì˜ˆì‹œ ì œì‹œ, ì „ëµ ëŒ€ì•ˆ ì œì•ˆ ë“±ë„ í¬í•¨í•´ì¤˜

ğŸ“Œ ë‹µë³€ í˜•ì‹ ì§€ì¹¨:
- ì¼ë°˜ì ì¸ ë¶„ì„/í•´ì„ì€ 3~4ì¤„ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½
- ì „ëµ ì œì•ˆ, ì°¨ë³„í™” ì•„ì´ë””ì–´, ë©”ë‰´ ì¶”ì²œ ë“±ì€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ë‚˜ì—´
- ìˆ«ìë‚˜ ì§€í‘œëŠ” ì •í™•íˆ í¬í•¨ (ì˜ˆ: "5ë…„ ìƒì¡´ìœ¨ 50.7%")
"""

def get_specific_instructions(report_type: str) -> str:
    if report_type == "ì°½ì—… ì¤€ë¹„":
        return """
        [ì‚¬ìš©ì í”„ë¡œí•„]
        - ì°½ì—… ê²½í—˜ì´ ì—†ëŠ” ì˜ˆë¹„ ì‚¬ì¥ë‹˜
        - ì—…ì¢…Â·ìƒê¶Œ ë¶„ì„ì— ëŒ€í•œ ì§€ì‹ì´ ê±°ì˜ ì—†ê³ , ì „ë¬¸ ìš©ì–´ ì´í•´ë„ê°€ ë‚®ìŒ
        - ì‚¬ì—… ê³„íš ìˆ˜ë¦½ì´ ì²˜ìŒì´ë©°, ìë³¸ê³¼ ë¦¬ìŠ¤í¬ì— ë¯¼ê°í•¨

        [ë‹µë³€ í†¤ & ìŠ¤íƒ€ì¼]
        - ì‰½ê³  ì¹œê·¼í•œ ì–´íˆ¬, ì „ë¬¸ ìš©ì–´ëŠ” í’€ì–´ì„œ ì„¤ëª…
        - ë‹¨ê³„ë³„ ì ‘ê·¼(1ë‹¨ê³„, 2ë‹¨ê³„...) êµ¬ì¡°ë¡œ ì•ˆë‚´
        - ë¹„ìœ , ì‚¬ë¡€ë¥¼ í™œìš©í•´ ì§ê´€ì  ì´í•´ë¥¼ ë•ê¸°
        - ë¶ˆí•„ìš”í•œ ë°ì´í„° ê³¼ì‰ ì œê³µ ëŒ€ì‹  í•µì‹¬ ì§€í‘œë§Œ ëª…í™•íˆ ì œì‹œ

        [ë‚´ìš© ìš°ì„ ìˆœìœ„]
        1) ìƒê¶ŒÂ·ì„ëŒ€ë£ŒÂ·ìœ ë™ì¸êµ¬ ë“± ê¸°ì´ˆ ì§€í‘œì˜ ì˜ë¯¸ì™€ í•´ì„
        2) ì°½ì—… ì¤€ë¹„ ì ˆì°¨ì™€ ì²´í¬ë¦¬ìŠ¤íŠ¸
        3) ë¹„ìš© ì ˆê° ë° ë¦¬ìŠ¤í¬ ìµœì†Œí™” íŒ
        4) ì—…ì¢…Â·ì…ì§€ë³„ ì„±ê³µ ì‚¬ë¡€ ì†Œê°œ
        """
    elif report_type == "ì‹œì¥ì¡°ì‚¬":
        return """
        [ì‚¬ìš©ì í”„ë¡œí•„]
        - í˜„ì¬ ë§¤ì¥ì„ ìš´ì˜ ì¤‘ì¸ í˜„ì§ ì‚¬ì¥ë‹˜
        - ì—…ì¢… ìš´ì˜ ê²½í—˜ì´ ìˆìœ¼ë©°, í˜„ ë§¤ì¶œÂ·ê³ ê° ë°ì´í„° ë³´ìœ 
        - ì‹ ì œí’ˆ ì¶œì‹œ, ë§ˆì¼€íŒ… ì „ëµ ë³€ê²½, í™•ì¥ ê°€ëŠ¥ì„± í‰ê°€ë¥¼ ìœ„í•´ ì‹œì¥ ë™í–¥ì´ í•„ìš”í•¨

        [ë‹µë³€ í†¤ & ìŠ¤íƒ€ì¼]
        - ì „ë¬¸ì ì´ê³  ë¶„ì„ì ì¸ ì–´íˆ¬
        - ë°ì´í„°ì™€ ìˆ˜ì¹˜ë¥¼ ê·¼ê±°ë¡œ ê²°ë¡  ì œì‹œ
        - í†µê³„, ë¹„êµ ë¶„ì„, ì—…ê³„ íŠ¸ë Œë“œë¥¼ ì ê·¹ í™œìš©
        - ì‹¤í–‰ ì „ëµì€ êµ¬ì²´ì ì´ê³  ROI ì¤‘ì‹¬ìœ¼ë¡œ ì œì•ˆ

        [ë‚´ìš© ìš°ì„ ìˆœìœ„]
        1) í˜„ì¬ ì‹œì¥ ì ìœ ìœ¨Â·ì„±ì¥ë¥ Â·ì†Œë¹„ íŠ¸ë Œë“œ
        2) ê²½ìŸì‚¬ ë¶„ì„(ê°€ê²©Â·ìƒí’ˆÂ·ë§ˆì¼€íŒ… ì „ëµ)
        3) ë§¤ì¶œ í™•ëŒ€ ê°€ëŠ¥ì„±ì´ ë†’ì€ í’ˆëª©ê³¼ ì±„ë„
        4) ë‹¨ê¸°Â·ì¤‘ì¥ê¸° ì‹œì¥ ë¦¬ìŠ¤í¬ ìš”ì¸
        """
    elif report_type == "í™•ì¥":
        return """
        [ì‚¬ìš©ì í”„ë¡œí•„]
        - ê¸°ì¡´ ë§¤ì¥ì„ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ ì¤‘ì¸ ì‚¬ì¥ë‹˜
        - ì‹ ê·œ ì§€ì  ì¶œì  ë˜ëŠ” ë¸Œëœë“œ í™•ì¥ì„ ê³ ë ¤ ì¤‘
        - ìš´ì˜ íš¨ìœ¨, ì¸ë ¥ ê´€ë¦¬, ìë³¸ ë°°ë¶„ì— ê´€ì‹¬ì´ ë†’ìŒ

        [ë‹µë³€ í†¤ & ìŠ¤íƒ€ì¼]
        - íˆ¬ìì ë³´ê³ ì„œì²˜ëŸ¼ ë…¼ë¦¬ì Â·ê³„ì‚°ì ì¸ ì„¤ëª…
        - ë¹„ìš© êµ¬ì¡°ì™€ ìˆ˜ìµì„± ë¶„ì„ ê°•ì¡°
        - ì§€ì—­Â·ìƒê¶Œ í¬í™”ë„ì™€ ê²½ìŸ ë¶„ì„ í¬í•¨
        - í™•ì¥ ì‹œ ì˜ˆìƒë˜ëŠ” ë¦¬ìŠ¤í¬ì™€ ëŒ€ì•ˆ ì œì‹œ

        [ë‚´ìš© ìš°ì„ ìˆœìœ„]
        1) ì‹ ê·œ ì…ì§€ì˜ ìƒê¶Œ ë¶„ì„(ìœ ë™ì¸êµ¬Â·ì„ëŒ€ë£ŒÂ·ê²½ìŸ ê°•ë„)
        2) ê¸°ì¡´ ë§¤ì¥ê³¼ì˜ ì‹œë„ˆì§€ íš¨ê³¼ ê°€ëŠ¥ì„±
        3) í™•ì¥ì— ë”°ë¥¸ ë¹„ìš© êµ¬ì¡° ë³€í™”ì™€ ìˆ˜ìµì„± ì˜ˆì¸¡
        4) ì¥ê¸° ì„±ì¥ ì „ëµê³¼ í™•ì¥ ì†ë„ ì¡°ì ˆ ë°©ì•ˆ
        """
    return ""

def format_history(history: List[Dict]) -> str:
    if not history:
        return ""
    lines = []
    for h in history:
        role = h.get("role", "user")
        content = h.get("content", "")
        if not content:
            continue
        who = "ì‚¬ìš©ì" if role == "user" else "ì»¨ì„¤í„´íŠ¸"
        lines.append(f"{who}: {content}")
    return "\n".join(lines)

prompt_template = PromptTemplate(
    template=(
        system_context + "\n\n"
        "{specific}\n\n"
        "[ì´ì „ ëŒ€í™” ê¸°ë¡]\n{history}\n\n"
        "[ë ˆí¬íŠ¸ ì¢…ë¥˜: {report_type}]\n"
        "[ë¶„ì„ ì§€ì—­: {location}]\n[ë¶„ì„ ì—…ì¢…: {category}]\n"
        "[ë¬¸ì„œ ìš”ì•½ ì •ë³´]\n{context}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{question}"
    ),
    input_variables=["context", "question", "location", "category", "report_type", "specific", "history"]
)

def get_response_with_rag(
    query: str,
    vectorstore_path: Optional[str] = None,
    context: str = "",
    location: str = "",
    category: str = "",
    report_type: str = "",
    history: Optional[List[Dict]] = None,
) -> str:
    """
    RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±.
    - vectorstore_path ë¯¸ì§€ì • ì‹œ config.VECTOR_DB_DIR ì‚¬ìš©
    - history: [{role:'user'|'assistant'|'bot', content:str}, ...]
    """
    # 1) ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    path = vectorstore_path or VECTOR_DB_DIR
    try:
        db = FAISS.load_local(
            folder_path=path,
            embeddings=embedding,
            allow_dangerous_deserialization=True
        )
    except Exception as e:
        return f"ì§€ì‹ë² ì´ìŠ¤ë¥¼ ì•„ì§ ì¤€ë¹„í•˜ì§€ ëª»í–ˆì–´ìš”. (ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ: {path})\nê´€ë¦¬ì: ì¸ë±ìŠ¤ë¥¼ ë¨¼ì € ìƒì„±í•´ ì£¼ì„¸ìš”. ìƒì„¸: {e}"

    retriever = db.as_retriever()

    # 2) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ ê°±ì‹ 
    try:
        docs = retriever.invoke(query)
        if docs:
            context = "\n\n".join([getattr(d, "page_content", "") for d in docs if getattr(d, "page_content", "")])
    except Exception as e:
        # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œì—ë„ ìµœì†Œ ë™ì‘
        context = context or ""
    
    # 3) report_typeë³„ ì„¸ë¶€ ì§€ì‹œë¬¸
    specific_instructions = get_specific_instructions(report_type)

    # 4) í”„ë¡¬í”„íŠ¸ + LLM ì‹¤í–‰
    chain = LLMChain(llm=llm, prompt=prompt_template)
    out = chain.invoke({
        "context": context,
        "question": query,
        "location": location,
        "category": category,
        "report_type": report_type,
        "specific": specific_instructions,
        "history": format_history(history or []),
    })
    return out["text"] if isinstance(out, dict) else str(out)
